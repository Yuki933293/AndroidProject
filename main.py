import time
import os
import subprocess
import audioop
from dataclasses import dataclass
import speech_recognition as sr
import pyttsx3
import dashscope
try:
    from dashscope.version import __version__ as dashscope_version
except ImportError:
    dashscope_version = None
from dashscope import Application
from dashscope.audio.asr.recognition import Recognition, RecognitionCallback
from http import HTTPStatus

# ================= é…ç½®åŒºåŸŸ =================
# æ‰“å°å½“å‰ dashscope SDK ç‰ˆæœ¬ï¼Œä¾¿äºå®šä½å…¼å®¹æ€§é—®é¢˜
DASHSCOPE_SDK_VERSION = getattr(dashscope, '__version__',
                                dashscope_version or 'unknown')
print(f"[INFO] dashscope SDK version: {DASHSCOPE_SDK_VERSION}")

# 1. è®¾ç½®æ‚¨çš„é˜¿é‡Œäº‘ç™¾ç‚¼ API KEY
dashscope.api_key = 'sk-fb64515c017945fc9282f9ace355cad3' 

# 2. è®¾ç½®æ‚¨çš„åº”ç”¨ ID (ä»æ‚¨æˆªå›¾çš„æ§åˆ¶å°è·å–)
APP_ID = '16356830643247938dfa31f8414fd58d' 
# ===========================================

# åƒé—® ASR æ¨¡å‹é…ç½®ï¼ˆåˆ‡æ¢åˆ° 16k ç‰ˆæœ¬ï¼Œæ•ˆæœæ›´ç¨³ï¼‰
# å®˜æ–¹æ¨¡å‹ ID ä½¿ç”¨è‹±æ–‡æ ‡è¯†ï¼Œé¿å… ModelNotFound
QWEN_ASR_MODEL = 'paraformer-realtime-8k-v2'
QWEN_ASR_SAMPLE_RATE = 8000

# ç®€å• ASR å›è°ƒå ä½ï¼Œä¸»è¦ç”¨äºæ»¡è¶³ Recognition æ„é€ è¦æ±‚
class SimpleASRCallback(RecognitionCallback):
    def on_open(self): pass
    def on_complete(self): pass
    def on_error(self, result): pass
    def on_close(self): pass
    def on_event(self, result): pass

# æ’­æ”¾çŠ¶æ€æ ‡è®°ï¼ˆåŠåŒå·¥ï¼‰
is_playing: bool = False

# è¿ç»­æµå¼å½•éŸ³ï¼ŒåŸºäºèƒ½é‡æ£€æµ‹çš„ç®€å• VADï¼šæœ‰å£°ç»§ç»­å½•ï¼Œé™éŸ³è¶…è¿‡é˜ˆå€¼ååœæ­¢
def record_with_vad(source,
                    max_duration: float = 30.0,
                    silence_duration: float = 2,
                    chunk_size: int = 1024):
    frames = []
    start_time = time.time()
    last_voice_time = time.time()

    while True:
        if time.time() - start_time > max_duration:
            break
        try:
            data = source.stream.read(chunk_size)
        except OverflowError:
            continue
        frames.append(data)
        energy = audioop.rms(data, source.SAMPLE_WIDTH)
        if energy > r.energy_threshold:
            last_voice_time = time.time()
        if (time.time() - last_voice_time) >= silence_duration and len(frames) > 5:
            break

    raw_data = b"".join(frames)
    return sr.AudioData(raw_data, source.SAMPLE_RATE, source.SAMPLE_WIDTH)


# ä½¿ç”¨åƒé—® ASR è¯†åˆ«æœ¬åœ°éŸ³é¢‘ï¼ˆwav/pcmï¼‰
def qwen_asr_transcribe(audio_bytes: bytes,
                        sample_rate: int = QWEN_ASR_SAMPLE_RATE) -> str | None:
    temp_path = 'temp_input.wav'
    try:
        with open(temp_path, 'wb') as f:
            f.write(audio_bytes)

        asr = Recognition(model=QWEN_ASR_MODEL,
                          callback=SimpleASRCallback(),
                          format='wav',
                          sample_rate=sample_rate)
        result = asr.call(temp_path)
        sentence = result.get_sentence()
        print(f"[DEBUG] ASR status={result.status_code}, code={result.code}, msg={result.message}, raw_sentence={sentence}")

        text = None
        if isinstance(sentence, list):
            # å–æœ€åä¸€å¥æœ‰æ•ˆæ–‡æœ¬
            for item in reversed(sentence):
                if isinstance(item, dict):
                    text = item.get('text') or item.get('result')
                    if text:
                        break
        elif isinstance(sentence, dict):
            text = sentence.get('text') or sentence.get('result')

        if text:
            return text

        print(f"[DEBUG] ASR è¿”å›æ— æ³•è§£æ: {sentence}")
        return None
    except Exception as e:
        print(f"[DEBUG] åƒé—® ASR è°ƒç”¨å¼‚å¸¸: {e}")
        return None


# åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨ ASR 
r = sr.Recognizer()

def speak(text, t_llm_last: float | None = None):
    print(f"ğŸ¤– æ™ºèƒ½ä½“æ­£åœ¨ç”Ÿæˆè¯­éŸ³: {text} ...")
    global is_playing
    is_playing = True
    try:
        # ä½¿ç”¨ macOS å†…ç½® say å‘½ä»¤è¿›è¡Œ TTS æ’­æ”¾
        subprocess.run(["say", text], check=False)
    finally:
        is_playing = False

def listen():
    # åŠåŒå·¥ï¼šè‹¥æœºå™¨äººåœ¨æ’­æŠ¥ï¼Œå…ˆç­‰å¾…æ’­æŠ¥ç»“æŸ
    while is_playing:
        time.sleep(0.05)

    with sr.Microphone(sample_rate=QWEN_ASR_SAMPLE_RATE) as source:
        print("\nğŸ‘‚ æ­£åœ¨è†å¬... (è¯·è¯´è¯)")
        # è‡ªåŠ¨è°ƒæ•´ç¯å¢ƒå™ªéŸ³
        r.adjust_for_ambient_noise(source, duration=0.5)
        try:
            print("Processing (VAD æ¨¡å¼ï¼Œé™éŸ³å°†è‡ªåŠ¨ç»“æŸ)...")
            audio = record_with_vad(source,
                                    max_duration=30.0,
                                    silence_duration=1.2,
                                    chunk_size=1024)
            wav_data = audio.get_wav_data(convert_rate=QWEN_ASR_SAMPLE_RATE,
                                          convert_width=2)
            text = qwen_asr_transcribe(wav_data)
            if text:
                print(f"ğŸ‘¤ æ‚¨è¯´: {text}")
            else:
                print("...ASR æœªè¯†åˆ«å‡ºæœ‰æ•ˆæ–‡æœ¬")
            return text
        except sr.WaitTimeoutError:
            print("...è¶…æ—¶æœªæ£€æµ‹åˆ°è¯­éŸ³")
            return None
        except sr.UnknownValueError:
            print("...æ— æ³•ç†è§£éŸ³é¢‘")
            return None

def chat_with_agent(prompt):
    """è°ƒç”¨ç™¾ç‚¼æ™ºèƒ½ä½“"""
    try:
        response = Application.call(
            app_id=APP_ID,
            prompt=prompt,
            # session_id å¯ä»¥åœ¨è¿™é‡Œç»´æŠ¤ä»¥å®ç°å¤šè½®å¯¹è¯è®°å¿†ï¼Œæœ¬ç¤ºä¾‹ç®€åŒ–å¤„ç†
        )

        if response.status_code != HTTPStatus.OK:
            print(f'âŒ è¯·æ±‚å¤±è´¥: {response.message}')
            return "å¯¹ä¸èµ·ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¤´æ™•ï¼Œè¯·ç¨åå†è¯•ã€‚"
        
        return response.output.text

    except Exception as e:
        print(f"âŒ è°ƒç”¨å¼‚å¸¸: {e}")
        return "ç³»ç»Ÿå‡ºé”™äº†ã€‚"

def main():
    speak("ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„æ™ºèƒ½ç®¡å®¶ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ï¼Ÿ")
    
    while True:
        # 1. å¬
        user_text = listen()
        
        if user_text:
            # é€€å‡ºæœºåˆ¶
            if "å†è§" in user_text or "é€€å‡º" in user_text:
                speak("å¥½çš„ï¼Œå†è§ï¼")
                break
            
            # 2. æƒ³ (å‘é€ç»™ç™¾ç‚¼)
            llm_end_ts = None
            reply_text = chat_with_agent(user_text)
            llm_end_ts = time.time()
            
            # 3. è¯´
            speak(reply_text, t_llm_last=llm_end_ts)
        
        # ç®€å•é˜²åˆ·å±ç­‰å¾…
        time.sleep(0.5)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²æ‰‹åŠ¨åœæ­¢")
